<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Getting Started with Reinforcement Learning | Jet New</title> <meta name="author" content="Jet New"> <meta name="description" content="A curation of resources for reinforcement learning."> <meta name="keywords" content="data-science, software-engineering, research, technology, entrepreneurship"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%99%9F%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="/blog/2021/rl-resources/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jet </span>New</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Getting Started with Reinforcement Learning</h1> <p class="post-meta">July 7, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/research"> <i class="fas fa-hashtag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <h2 id="what-is-reinforcement-learning-rl">What is Reinforcement Learning (RL)?</h2> <p>You may have heard about the successes of artificial intelligence (AI) over humans in games such as Go (<a href="https://www.bbc.com/news/technology-50573071" rel="external nofollow noopener" target="_blank">Go master quits because AI ‘cannot be defeated’</a>), StarCraft (<a href="https://www.theverge.com/2019/10/30/20939147/deepmind-google-alphastar-starcraft-2-research-grandmaster-level" rel="external nofollow noopener" target="_blank">DeepMind’s StarCraft 2 AI is now better than 99.8 percent of all human players</a>) and DoTA 2 (<a href="https://www.theverge.com/2019/4/13/18309459/openai-five-dota-2-finals-ai-bot-competition-og-e-sports-the-international-champion" rel="external nofollow noopener" target="_blank">OpenAI’s Dota 2 AI steamrolls world champion e-sports team with back-to-back victories</a>).</p> <p>The core technology behind these AI successes is reinforcement learning. Reinforcement learning is a <a href="https://en.wikipedia.org/wiki/Machine_learning" rel="external nofollow noopener" target="_blank">machine learning</a> paradigm (alongside supervised and unsupervised learning) that learns an optimal sequence of actions to take in the environment. In contrast, <a href="https://en.wikipedia.org/wiki/Supervised_learning" rel="external nofollow noopener" target="_blank">supervised learning</a> learns a single output prediction based on an existing training dataset of labels, and <a href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="external nofollow noopener" target="_blank">unsupervised learning</a> learns the distribution of data without any given labels.</p> <p>As you may have expected, reinforcement learning is closely related to (and is in fact inspired by) the same concept behind <a href="https://en.wikipedia.org/wiki/Classical_conditioning" rel="external nofollow noopener" target="_blank">Pavlov’s Dog</a>, operant conditioning. <a href="https://en.wikipedia.org/wiki/Operant_conditioning" rel="external nofollow noopener" target="_blank">Operant conditioning</a> is a learning process that associates and modifies behaviours with reinforcement or punishment. This is well described by psychologist <a href="https://en.wikipedia.org/wiki/Edward_Thorndike" rel="external nofollow noopener" target="_blank">Edward Thorndike</a>’s <a href="https://en.wikipedia.org/wiki/Law_of_effect" rel="external nofollow noopener" target="_blank">Law of Effect</a>, which states:</p> <blockquote> <p>“Responses that produce a satisfying effect in a particular situation become more likely to occur again in that situation, and responses that produce a discomforting effect become less likely to occur again in that situation.”</p> </blockquote> <p>The process of reinforcement learning takes place in 4 stages:</p> <ol> <li>The environment’s state is first observed by the agent.</li> <li>The agent takes an action based on the observation.</li> <li>The agent’s action influences the environment’s state.</li> <li>The environment then returns a new state to the agent, along with a reward indicating the goodness of the action taken.</li> </ol> <p>Reinforcement learning is currently used by a few applications in industry, namely <a href="https://venturebeat.com/2021/02/23/how-reinforcement-learning-chooses-the-ads-you-see/" rel="external nofollow noopener" target="_blank">recommending personalised advertisements</a>, improving search engines, and more recently, <a href="https://engineering.grab.com/understanding-supply-demand-ride-hailing-data" rel="external nofollow noopener" target="_blank">improving pricing algorithms</a> of ride-hailing applications based on live demand and supply. While RL currently does not have as many applications as domains like <a href="https://en.wikipedia.org/wiki/Computer_vision" rel="external nofollow noopener" target="_blank">computer vision</a> and <a href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="external nofollow noopener" target="_blank">natural language processing</a>, RL is a promising and upcoming method with high potential in fields like <a href="https://bair.berkeley.edu/blog/2020/04/27/ingredients/" rel="external nofollow noopener" target="_blank">robotics</a> (think automating thousands of manual processes in factories), self-driving vehicles (think reducing accident rates while significantly improving logistics transportation efficiency) and, of course, video games (who doesn’t enjoy seeing games being solved/mastered?)</p> <p>Reinforcement learning can seem quite intimidating to beginners due to the vastness of the field. In this blog article, I will share the resources and some advice on how to use them effectively to get started with learning reinforcement learning. These recommendations are heavily opinionated based on my own learning journey in RL.</p> <hr> <h2 id="introductory-reinforcement-learning">Introductory Reinforcement Learning</h2> <p>Reinforcement learning is a sub-field of machine learning, and so learning RL will require learning machine learning. You should also learn RL in consideration of mathematical theory and practical coding. The following 3 resources are thus recommended based on those considerations.</p> <h3 id="1-machine-learning-crash-course-by-google">1. <a href="https://developers.google.com/machine-learning/crash-course/ml-intro" rel="external nofollow noopener" target="_blank">Machine Learning Crash Course</a> by Google</h3> <p>Reinforcement learning requires many concepts from machine learning (ML). This crash course (that contains mainly explanatory videos) provides an introductory understanding to the main ML concepts that you will need for RL. Some concepts covered: Training vs Validation vs Testing, Classification vs Regression, Introductory Neural Networks.</p> <h3 id="2-reinforcement-learning-a-tutorial-by-harmon--harmon">2. <a href="http://www.cs.toronto.edu/~zemel/documents/411/rltutorial.pdf" rel="external nofollow noopener" target="_blank">Reinforcement Learning: A Tutorial</a> by Harmon &amp; Harmon</h3> <p>This tutorial presents the theory of RL at an introductory level. It formalises the RL paradigm with math, and is a great resource so that concepts are rigorous and not too hand-wavy. The math and notation may make it look intimidating, but if you understand the underlying motivation and concepts, understanding the notation will come naturally. Follow through thoroughly and you will be rewarded well. Topics covered: Dynamic programming, Value iteration, Q-learning, Temporal difference learning, Discounting rewards. Nonetheless, even if you’re unable to follow through, you should still face no problem proceeding with the next resource on Medium.</p> <h3 id="3-deep-rl-course-on-medium-by-thomas-simonini">3. <a href="https://simoninithomas.github.io/deep-rl-course/" rel="external nofollow noopener" target="_blank">Deep RL Course on Medium</a> by Thomas Simonini</h3> <p>This Medium series on deep RL (deep because it uses deep neural networks) is one of the best courses for learning introductory deep RL with a good balance of practical coding and RL theory. Topics covered: Deep Q-learning, Policy Gradients, Actor Critics, Unity-ML Agents. The resources up to actor critics are excellent; Learning Unity-ML Agents is optional, learn it if you are interested in the Unity-ML Agents environments.</p> <hr> <h2 id="tools-for-reinforcement-learning">Tools for Reinforcement Learning</h2> <h3 id="1-rl-gym-environments">1. RL Gym Environments</h3> <p>RL Gym environments are the simulation software that is used to train RL agents in. They’re called “gyms” because of <a href="https://gym.openai.com/" rel="external nofollow noopener" target="_blank">OpenAI gym</a>’s standardisation of environment APIs. There are too many RL environments, but here are some lists to refer to: <a href="https://github.com/clvrai/awesome-rl-envs" rel="external nofollow noopener" target="_blank">awesome-rl-envs</a>, <a href="https://github.com/tshrjn/env-zoo" rel="external nofollow noopener" target="_blank">env-zoo</a> and <a href="https://github.com/kengz/awesome-deep-rl" rel="external nofollow noopener" target="_blank">awesome-deep-rl</a>. The RL environments are diverse and many are really cool, such as IKEA furniture assembly, Retro games and autonomous vehicle simulators.</p> <h3 id="2-rl-frameworks">2. RL Frameworks</h3> <p>RL frameworks are frameworks made specifically for building RL agents and/or training them. While most RL research work use general deep learning frameworks, e.g. <a href="https://pytorch.org/" rel="external nofollow noopener" target="_blank">PyTorch</a>, <a href="https://www.tensorflow.org/" rel="external nofollow noopener" target="_blank">TensorFlow</a>, <a href="https://jax.readthedocs.io/en/latest/index.html" rel="external nofollow noopener" target="_blank">JAX</a>, <a href="https://github.com/google/flax" rel="external nofollow noopener" target="_blank">FLAX</a>, <a href="https://www.pytorchlightning.ai/" rel="external nofollow noopener" target="_blank">Pytorch Lightning</a>, <a href="https://www.tensorflow.org/probability" rel="external nofollow noopener" target="_blank">TensorFlow Probability</a>, there are also RL frameworks available. There is currently no established “best” RL frameworks yet due to the diversity of RL concepts, but I found <a href="https://stable-baselines3.readthedocs.io/en/master/" rel="external nofollow noopener" target="_blank">Stable Baselines</a> (recently version 3) very useful for basic usage of RL. <a href="https://www.tensorflow.org/agents" rel="external nofollow noopener" target="_blank">TensorFlow Agents</a> is a library used by some companies in industry. <a href="https://github.com/seungeunrho/minimalRL" rel="external nofollow noopener" target="_blank">minimalRL</a> and <a href="https://docs.cleanrl.dev/" rel="external nofollow noopener" target="_blank">CleanRL</a> are repositories of minimal code implementations of RL algorithms in PyTorch that is useful for learning.</p> <hr> <h2 id="intermediate-reinforcement-learning">Intermediate Reinforcement Learning</h2> <p>Reinforcement learning is a vast field that contains many different concepts (many inspired by cognitive neuroscience). Behaviours are influenced and controlled by many mechanisms and so many methods are available in reinforcement learning. This section will provide some tips on exploring the many domains in RL, e.g. Exploration, Memory, Model-based. It is important to note the difference between “RL” and “deep RL”, the former being about traditional RL while the latter about applying neural networks to RL.</p> <h3 id="1-reinforcement-learning-an-introduction-by-richard-s-sutton-and-andrew-g-barto">1. <a href="http://incompleteideas.net/book/the-book.html" rel="external nofollow noopener" target="_blank">Reinforcement Learning: An Introduction</a> by Richard S. Sutton and Andrew G. Barto</h3> <p>Sutton and Barto is a good <strong>textbook</strong> on RL that is commonly coined the RL “bible” for its prominence. The textbook is a comprehensive resource and reference for RL, covering tabular methods such as multi-armed bandits, dynamic programming, Monte Carlo methods, TD-learning and bootstrapping, to approximate methods for prediction and control and policy gradients.</p> <h3 id="2-introduction-to-reinforcement-learning-by-david-silver-deepmind">2. <a href="https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver" rel="external nofollow noopener" target="_blank">Introduction to Reinforcement Learning</a> by David Silver, DeepMind</h3> <p>Intro to RL by David Silver, DeepMind is a good <strong>lecture</strong> series on reinforcement learning. It formulates RL with concepts about Markov decision processes, planning by dynamic programming, prediction vs control, value function approximation, among others. David Silver is a RL pioneer who co-authored <a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" rel="external nofollow noopener" target="_blank">Playing Atari with Deep Reinforcement Learning</a>, one of the first successful attempts to apply deep neural networks to reinforcement learning.</p> <h3 id="3-reinforcement-learning-specialization-on-coursera-by-university-of-alberta">3. <a href="https://www.coursera.org/specializations/reinforcement-learning" rel="external nofollow noopener" target="_blank">Reinforcement Learning Specialization on Coursera</a> by University of Alberta</h3> <p>The RL Specialization on Coursera is a good <strong>course</strong> on RL, introducing concepts such as temporal difference learning, Monte Carlo, Sarsa, Q-learning, policy gradients, the Dyna architecture, and more. The course is taught by Martha White and Adam White, who are students of Richard Sutton, the author of the Reinforcement Learning: An Introduction textbook (<a href="https://www.reddit.com/r/MachineLearning/comments/h940xb/what_is_the_best_way_to_learn_about_reinforcement/" rel="external nofollow noopener" target="_blank">who personally recommended the course</a>).</p> <h3 id="4-spinning-up-key-papers-in-deep-rl-by-openai">4. <a href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html" rel="external nofollow noopener" target="_blank">Spinning Up: Key Papers in Deep RL</a> by OpenAI</h3> <p>Spinning Up by OpenAI is a resource that introduces deep RL concepts to people interested in picking up RL. Their Key Papers in Deep RL section provides a good starting point to the overview of RL topics, introducing milestone research papers in each topic. Examples: Model-Free RL, Exploration, Transfer and Multitask RL, Hierarchy, Memory, etc.</p> <h3 id="5-cs285-deep-reinforcement-learning-by-sergey-levine-uc-berkeley">5. <a href="http://rail.eecs.berkeley.edu/deeprlcourse/" rel="external nofollow noopener" target="_blank">CS285: Deep Reinforcement Learning</a> by Sergey Levine, UC Berkeley</h3> <p>CS285 is a good <strong>lecture</strong> series on deep reinforcement learning, with concepts covering policy gradients, actor-critics, model-based RL, exploration, offline RL, inverse RL and meta-learning in RL, among others. Offline RL is used to train an RL agent offline (i.e. collect a batch of interactions then training the agent on it). Inverse RL involves using interaction data from a human expert and is used to infer the RL policy underlying the human decision making process. Sergey Levine is a prominent RL researcher and his course provides many good insights into deep RL.</p> <h3 id="6-algorithms-for-decision-making-by-mykel-j-kochenderfer-tim-a-wheeler-and-kyle-h-wray">6. <a href="https://algorithmsbook.com" rel="external nofollow noopener" target="_blank">Algorithms for Decision Making</a> by Mykel J. Kochenderfer, Tim A. Wheeler and Kyle H. Wray</h3> <p>Algorithms for Decision Making is a good and updated (2022) <strong>textbook</strong> that serves as a modern perspective of the problems in the field of reinforcement learning. In particular, it delivers a detailed walkthrough of belief state planning and multi-agent systems compared to Sutton &amp; Barto, and contains beautiful illustrations for explanations, complete with code implementations in Julia.</p> <hr> <h2 id="advanced-reinforcement-learning">Advanced Reinforcement Learning</h2> <p>Beyond the standard learning resources are the topics that are active and unsolved open research questions. At this point, the research community is your best friend. The following resources and advice are strategies I found useful in my own learning journey.</p> <h3 id="1-survey-research-papers">1. Survey Research Papers</h3> <p>While there are many research papers that are impossible to read them all, there are survey papers that provide an overview of the current research landscape and topics. These survey papers provide an outline of the field and importantly introduce terminology that you can use to further search for what you are interested in. For example, <a href="https://arxiv.org/pdf/cs/9605103.pdf" rel="external nofollow noopener" target="_blank">Reinforcement Learning: A Survey</a> (Kaelbling et al. 1996) surveys the field of RL from a computer science perspective. For a more updated survey on deep RL, refer to <a href="https://discovery.ucl.ac.uk/id/eprint/10083557/1/1708.05866v2.pdf" rel="external nofollow noopener" target="_blank">A Brief Survey of Deep Reinforcement Learning</a> (Arulkumaran et al. 2017). I am personally interested in model-based reinforcement learning, so the following surveys served me well: <a href="https://arxiv.org/abs/2006.16712" rel="external nofollow noopener" target="_blank">Model-based Reinforcement Learning: A Survey</a> (Moerland et al. 2020), <a href="https://arxiv.org/abs/2008.05598" rel="external nofollow noopener" target="_blank">Deep Model-Based Reinforcement Learning for High-Dimensional Problems, a Survey</a> (Plaat et al. 2020). If you are interested in other domains in RL such as exploration or memory, you can search for terms terms like “reinforcement learning exploration survey” or “reinforcement learning memory survey” on Google Search or <a href="https://scholar.google.com/" rel="external nofollow noopener" target="_blank">Google Scholar</a>.</p> <h3 id="2-research-blogs--articles">2. Research Blogs / Articles</h3> <p>Blog posts are my personal favourite for developing an initial understanding of the research landscape or particular research papers. One of the most popular blogs is <a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html" rel="external nofollow noopener" target="_blank">Lilian Weng’s blog</a>, that covers many topics including RL, natural language processing, computer vision and representation learning. <a href="https://bair.berkeley.edu/blog/" rel="external nofollow noopener" target="_blank">Berkeley AI Research (BAIR)’s blog</a>, <a href="https://ai.googleblog.com/" rel="external nofollow noopener" target="_blank">Google AI Blog</a> and <a href="https://ai.facebook.com/blog/?page=1" rel="external nofollow noopener" target="_blank">Facebook AI Research (FAIR)’s blog</a> often blog about their RL papers. <a href="https://distill.pub" rel="external nofollow noopener" target="_blank">Distill</a> was a peer-reviewed journal (not a blog) that focuses on interactive articles about machine learning research topics, allowing for playable exploration on their articles.</p> <h3 id="3-youtube-channels">3. YouTube Channels</h3> <p>YouTube channels also provide good videos that explain papers or provide updates on the state of research. <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew" rel="external nofollow noopener" target="_blank">Yannic Kilcher</a> is a well-known YouTuber for his videos that explain recent hotly discussed papers. <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw/videos" rel="external nofollow noopener" target="_blank">Henry AI Labs</a> provide weekly updates about AI in general. <a href="https://www.youtube.com/channel/UCMLtBahI5DMrt0NPvDSoIRQ" rel="external nofollow noopener" target="_blank">Machine Learning Street Talk</a> conducts interviews with researchers to discuss about their research.</p> <h3 id="4-online-communities">4. Online Communities</h3> <p>Various online communities are active for research discussions as well, such as communities on Twitter or Reddit. Online communities are important because they foster discussion, debate and ideation. Twitter (or “Academic Twitter”) is a highly active community because many researchers tweet about their research. A list of researchers to follow on Twitter: <a href="https://www.reddit.com/r/MachineLearning/comments/b6dwrd/d_best_current_twitter_accounts_to_follow_for/" rel="external nofollow noopener" target="_blank">here</a>, but do actively adjust your Twitter feed according to your research interests. <a href="https://www.reddit.com/r/MachineLearning/" rel="external nofollow noopener" target="_blank">r/MachineLearning</a> is an active community that posts interesting research papers or discussion topics about ML research in general with thought-provoking comments. Or you could start your own a reading group!</p> <hr> <h2 id="conclusion">Conclusion</h2> <p>Reinforcement learning, as you now know, is such a vast and diverse field by nature that is still a highly active research area with many open problems. While RL is currently mainly used for ads, search and recommendation, RL holds great potential by unlocking automation of robotics, driverless vehicles and many other applications. With this article, I hope that it helps more people get into reinforcement learning and unlock the many things that can be done with RL. That said, again, this is an opinionated article based on my learning journey, and likely will change as I progress in my learning. If you have recommendations for resources or tips to include in this article, feel free to contact me at <a href="mailto:notesjet@gmail.com">notesjet@gmail.com</a>. Cheers!</p> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"jetnew/jetnew.github.io","data-repo-id":"R_kgDOGHdCoA","data-category":"Comments","data-category-id":"DIC_kwDOGHdCoM4CTEID","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Jet New. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-17NCYRPV4N"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-17NCYRPV4N");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>