<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Evolutionary Computation: Genetic Algorithm, Neuroevolution and Novelty Search | Jet New</title> <meta name="author" content="Jet New"> <meta name="description" content="A blog post on evolutionary computation, a family of optimization algorithms inspired by biological evolution."> <meta name="keywords" content="data-science, software-engineering, research, technology, entrepreneurship"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%99%9F%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="/blog/2020/evo-comp/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jet </span>New</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Evolutionary Computation: Genetic Algorithm, Neuroevolution and Novelty Search</h1> <p class="post-meta">November 28, 2020</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/tutorial"> <i class="fas fa-hashtag fa-sm"></i> tutorial</a>   <a href="/blog/tag/research"> <i class="fas fa-hashtag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <h2 id="genetic-algorithm">Genetic Algorithm</h2> <p>The genetic algorithm is a nature-inspired algorithm based on natural selection, that the fittest individuals of a population are selected to reproduce the next generation.</p> <p>The genetic algorithm consists of 5 processes:</p> <ol> <li>Initial population</li> <li>Fitness function</li> <li>Selection</li> <li>Crossing-over</li> <li>Mutation</li> </ol> <p>Terminology:</p> <ul> <li>Population refers to the set of individuals (solution).</li> <li>Individual is defined by its chromosome (set of parameters/variables).</li> <li>Fitness function refers to the performance measure of an individual.</li> <li>Selection refers to the selection of the fittest.</li> <li>Crossing-over refers to a swapping of segments of 2 parents’ genes, producing a child individual with a new gene combination.</li> <li>Mutation is a random perturbation of genes based on a probability.</li> </ul> <h3 id="optimization-problem-linear-regression">Optimization Problem: Linear Regression</h3> <p>Evolutionary algorithms can serve as “black box” optimisation algorithms without needing to solving the objective function analytically. To illustrate that evolutionary algorithms can optimise, the simple linear regression problem is used. Define a linear function:</p> \[y = mx + c + \epsilon\] <p>to be modelled by a linear regression model, where $m=1$, $c=0$, $\epsilon\sim N(0,1)$ represents gradient, y-intercept and Gaussian noise respectively.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># for reproducibility
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Linear function with Gaussian noise</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/linear_target.png" data-zoomable=""> </div> </div> <div class="caption"> Linear target function. </div> <h3 id="process-1-generate-the-initial-population-of-individuals">Process 1: Generate the initial population of individuals.</h3> <p>Each individual (solution/model) is defined by a set of parameters. Hyperparameters to be specified, which are variables that are not updated at every iteration of optimisation, are the population size (number of individuals in the population at any point in time) and the number of parameters that defines an individual. The initial population’s parameters can be zero-initialised or random-initialised. For your interest, there also exists many other initialisation methods to be used depending on context, such as the He initialisation and Xavier initialisation. The set of parameters that defines each individual is biologically analogous to the individual’s genome (or gene or chromosome, depending on the computational process).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">population_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_parameters</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># initial_population = np.zeros(shape=(population_size, num_parameters))  # zero initialisation
</span><span class="n">initial_population</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">population_size</span><span class="p">,</span> <span class="n">num_parameters</span><span class="p">))</span>  <span class="c1"># random normal initialisation
</span><span class="n">initial_population</span>


<span class="nf">array</span><span class="p">([[</span> <span class="mf">1.8831507</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.34775906</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.270485</span>  <span class="p">,</span>  <span class="mf">0.96939671</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.17312341</span><span class="p">,</span>  <span class="mf">1.94362119</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.41361898</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.74745481</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.92294203</span><span class="p">,</span>  <span class="mf">1.48051479</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.86755896</span><span class="p">,</span>  <span class="mf">0.90604466</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.86122569</span><span class="p">,</span>  <span class="mf">1.91006495</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.26800337</span><span class="p">,</span>  <span class="mf">0.8024564</span> <span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.94725197</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15501009</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.61407937</span><span class="p">,</span>  <span class="mf">0.92220667</span><span class="p">]])</span>
</code></pre></div></div> <h3 id="process-2-compute-the-fitness-of-all-individuals">Process 2: Compute the fitness of all individuals.</h3> <p>Another 2 hyperparameters are in the form of functions - the solution and the fitness function. The solution is a model that uses the individual’s parameters to compute the output $y$ given input $X$. For simplicity, we use the polynomial regression model (with 2 parameters, it is a simple linear regression model):</p> \[f(X) = \theta_1 X + \theta_2\] <p>where $\theta_1$ and $\theta_2$ should converge to $m$ and $c$ respectively eventually. The fitness function measures the performance of an individual solution. The evolutionary analogy of the fitness function of an organism would be, for example, its survivability and/or reproductive success. Because we want to model the linear function with Gaussian noise dataset, the negative mean squared error (MSE) is used as the fitness function to determine how well the solution models the dataset:</p> \[MSE = \frac{1}{n} \sum_{i=1}^n (y_{i} - f(X_i))^2\] <p>Because the fitness function is to be maximised, MSE is negated to reflect a higher value of MSE as more desirable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">solution</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>  <span class="c1"># Polynomial regression model
</span>  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">params</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>  <span class="c1"># Mean squared error
</span>  <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="nf">solution</span><span class="p">(</span><span class="n">params</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_data</span><span class="p">():</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_individual</span><span class="p">(</span><span class="n">individual</span><span class="p">):</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nf">solution</span><span class="p">(</span><span class="n">individual</span><span class="p">),</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">grey</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_population</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
    <span class="nf">plot_individual</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span>

<span class="n">individual</span> <span class="o">=</span> <span class="n">initial_population</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fitness_score</span> <span class="o">=</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span>

<span class="nf">plot_data</span><span class="p">()</span>
<span class="nf">plot_individual</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">plot_data</span><span class="p">()</span>
<span class="nf">plot_population</span><span class="p">(</span><span class="n">initial_population</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/individual_solution.png" data-zoomable=""> </div> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/initial_population.png" data-zoomable=""> </div> </div> <div class="caption"> Individual candidate solution (left) and initial population (right). </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">fitness_function</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span> <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">])</span>

<span class="n">fitness_scores</span> <span class="o">=</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">initial_population</span><span class="p">)</span>
<span class="n">fitness_scores</span>


<span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">145.00615079</span><span class="p">,</span>   <span class="o">-</span><span class="mf">3.20852429</span><span class="p">,</span>  <span class="o">-</span><span class="mf">21.20939814</span><span class="p">,</span> <span class="o">-</span><span class="mf">110.93013108</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">21.41800978</span><span class="p">,</span>   <span class="o">-</span><span class="mf">2.83355152</span><span class="p">,</span>  <span class="o">-</span><span class="mf">21.68891802</span><span class="p">,</span>   <span class="o">-</span><span class="mf">2.97834017</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">35.66225857</span><span class="p">,</span>   <span class="o">-</span><span class="mf">1.05527391</span><span class="p">])</span>
</code></pre></div></div> <h3 id="process-3-select-the-fittest-individuals">Process 3: Select the fittest individuals.</h3> <p>Like natural selection, select the top $k$ percentage of individuals with the highest fitness scores, where $k$ is a hyperparameter, to form the parent subpopulation that will reproduce to form the next generation of the population later.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">fitness_scores</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(),</span> <span class="p">:]</span>

<span class="k">def</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">fitness_scores</span><span class="p">)[</span><span class="o">-</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span><span class="p">):],</span> <span class="p">:]</span>

<span class="n">parent_subpopulation</span> <span class="o">=</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">initial_population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">parent_subpopulation</span><span class="p">,</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">parent_subpopulation</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([[1.86755896, 0.90604466],
        [0.61407937, 0.92220667]]), array([-2.83355152, -1.05527391]))
</code></pre></div></div> <h3 id="process-4-perform-crossing-over-between-parents-to-produce-children">Process 4: Perform crossing-over between parents to produce children.</h3> <p>Crossing-over is a biological process that exchanges genetic material to result in new combinations of genetic material. For the benefit of non-biology students, much detail has been abstracted out and interested readers can refer to chromosomal crossovers. In the genetic algorithm, crossing-over is performed during reproduction by swapping a segment of parameters of one parent with another parent. For example, take 2 parents defined by 4 parameters:</p> \[P1 = [A1, A2, A3, A4], P2 = [B1, B2, B3, B4]\] <p>A crossing-over at the index 3 will result in a child:</p> \[C = [A1, A2, B3, B4]\] <p>There exists other methods of genetic exchange to introduce variance in the population gene pool, such as swapping elements instead of segments.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">perform_crossingover</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">):</span>
  <span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">population_size</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">)):</span>
    <span class="n">parents</span> <span class="o">=</span> <span class="n">subpopulation</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">),</span> <span class="mi">2</span><span class="p">)]</span>
    <span class="n">gene_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">num_parameters</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">gene_indices</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">gene_indices</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># segment swap
</span>    <span class="n">child</span> <span class="o">=</span> <span class="n">parents</span><span class="p">[</span><span class="n">gene_indices</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_parameters</span><span class="p">)]</span>
    <span class="n">children</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">children</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">next_population</span> <span class="o">=</span> <span class="nf">perform_crossingover</span><span class="p">(</span><span class="n">parent_subpopulation</span><span class="p">)</span>
<span class="n">next_population</span><span class="p">,</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">next_population</span><span class="p">)</span>


<span class="p">(</span><span class="nf">array</span><span class="p">([[</span><span class="mf">1.86755896</span><span class="p">,</span> <span class="mf">0.90604466</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.86755896</span><span class="p">,</span> <span class="mf">0.90604466</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.86755896</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.86755896</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61407937</span><span class="p">,</span> <span class="mf">0.92220667</span><span class="p">]]),</span>
  <span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.83355152</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.05527391</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.05527391</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.83355152</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.05527391</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.05527391</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.04089715</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.05527391</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.04089715</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.05527391</span><span class="p">]))</span>
</code></pre></div></div> <h3 id="process-5-perform-mutation-on-the-population">Process 5: Perform mutation on the population.</h3> <p>A mutation is defined as a change in the DNA sequence. While the exact differences between DNA, gene and chromosome in the genetic algorithm are not maintained, inspiration is drawn from mutation in biology that usually worsens fitness but can occasionally improve fitness of the individual. To perform mutation on the population parameters, add Gaussian noise $\epsilon\sim N(0, \sigma)$ to the individuals’ parameters, where $\sigma$ is the standard deviation hyperparameter.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">population</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Gaussian noise
</span>
<span class="n">mutated_population</span> <span class="o">=</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">next_population</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">mutated_population</span><span class="p">,</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">mutated_population</span><span class="p">)</span>


<span class="p">(</span><span class="nf">array</span><span class="p">([[</span><span class="mf">1.86732417</span><span class="p">,</span> <span class="mf">0.90693888</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6081361</span> <span class="p">,</span> <span class="mf">0.9211497</span> <span class="p">],</span>
        <span class="p">[</span><span class="mf">0.62150733</span><span class="p">,</span> <span class="mf">0.91465686</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.86617613</span><span class="p">,</span> <span class="mf">0.88479546</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.60377918</span><span class="p">,</span> <span class="mf">0.91703215</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61266137</span><span class="p">,</span> <span class="mf">0.90944187</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.88237409</span><span class="p">,</span> <span class="mf">0.93879944</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61408077</span><span class="p">,</span> <span class="mf">0.93726506</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.86860417</span><span class="p">,</span> <span class="mf">0.91984624</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.62227372</span><span class="p">,</span> <span class="mf">0.92623524</span><span class="p">]]),</span>
  <span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.84393595</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0525611</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.05282308</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.58416917</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.04907953</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.04977737</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.3166936</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.07545786</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.01246558</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0622913</span> <span class="p">]))</span>
</code></pre></div></div> <h3 id="the-genetic-algorithm-all-5-processes-together">The Genetic Algorithm: All 5 Processes Together</h3> <p>By combining the 5 processes together, we construct the genetic algorithm and run it to find a solution that models the linear function well.</p> <p>Genetic Algorithm:</p> <ol> <li>Generate the initial population of individuals.</li> <li>Repeat until convergence: <ol> <li>Compute fitness of the population.</li> <li>Select the fittest individuals (parent subpopulation).</li> <li>Perform crossing-over between parents to produce children.</li> <li>Perform mutation on the population.</li> </ol> </li> <li>Select the fittest individual of the population as the solution.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define hyperparameters of the genetic algorithm.
</span><span class="n">population_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_parameters</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_generations</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">mutation_sigma</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Process 1: Generate the initial population of individuals.
</span><span class="n">population</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">population_size</span><span class="p">,</span> <span class="n">num_parameters</span><span class="p">))</span>

<span class="c1"># Misc: Experimental tracking
</span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">solutions</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterate the process over multiple generations of populations.
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>

  <span class="c1"># Process 2: Compute the fitness of all individuals.
</span>  <span class="n">fitness_scores</span> <span class="o">=</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

  <span class="c1"># Process 3: Select the fittest individuals.
</span>  <span class="n">fittest_subpopulation</span> <span class="o">=</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>
  
  <span class="c1"># Misc: Experimental tracking
</span>  <span class="n">fittest</span> <span class="o">=</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">)</span>
  <span class="n">solutions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">solution</span><span class="p">(</span><span class="n">fittest</span><span class="p">))</span>
  <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">fitness_function</span><span class="p">(</span><span class="n">fittest</span><span class="p">))</span>

  <span class="c1"># Process 4: Perform crossing-over between parents to produce children.
</span>  <span class="n">children</span> <span class="o">=</span> <span class="nf">perform_crossingover</span><span class="p">(</span><span class="n">fittest_subpopulation</span><span class="p">)</span>

  <span class="c1"># Process 5: Perform mutation on the population.
</span>  <span class="n">population</span> <span class="o">=</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">mutation_sigma</span><span class="p">)</span>


<span class="c1"># Misc: Experimental tracking
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_generations</span><span class="p">),</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/ga_training_plot.png" data-zoomable=""> </div> </div> <div class="caption"> Score over generations. </div> <h3 id="experiment-result">Experiment Result</h3> <p>The fittest individual in the final population is a reasonably well-fit linear regression model. The rest of the population have a lower fitness score but are quite well-fit as well.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fitness_score</span> <span class="o">=</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">solution</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>

<span class="nf">plot_data</span><span class="p">()</span>
<span class="nf">plot_individual</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">plot_data</span><span class="p">()</span>
<span class="nf">plot_population</span><span class="p">(</span><span class="n">fittest_subpopulation</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/individual_trained.png" data-zoomable=""> </div> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/population_trained.png" data-zoomable=""> </div> </div> <div class="caption"> Individual fitted solution (left) and fitted population (right). </div> <p>By visualising the fittest model at each generation (iteration) of the genetic algorithm, notice that virtually instantly, the linear regression model fits to the dataset. In fact, linear regression is too simple a problem to realise the effectiveness of the genetic algorithm. Nonetheless, the reason for using linear regression is to bring focus to the genetic algorithm without the overhead of needing to understand the model. For a more complex application of the genetic algorithm using neural networks, refer to the second section Neuroevolution. For an evolutionary strategy based on novelty applied on reinforcement learning, refer to the third section.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="kn">from</span> <span class="n">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="nf">plot_data</span><span class="p">()</span>
<span class="n">ga_line</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">([],</span> <span class="p">[])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">ga_line</span><span class="p">.</span><span class="nf">set_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">solutions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Gen </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ga_line</span><span class="p">,</span> <span class="n">ax</span>

<span class="n">ani</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_generations</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ani</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">/images/genetic-algorithm/genetic_algorithm.gif</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/genetic_algorithm.gif" data-zoomable=""> </div> </div> <div class="caption"> Genetic algorithm on linear regression over generations. </div> <hr> <h2 id="neuroevolution">Neuroevolution</h2> <p>Neuroevolution is a method of applying evolutionary algorithms to optimise neural networks instead of using backpropagation. Neuroevolution therefore is a non-gradient (or derivation-free) optimisation, which can speed up training as backward passes are not computed. The neural network optimised by neuroevolution can be adapted in terms of parameters, hyperparameters or network architecture. Prominent examples of neuroevolution are NeuroEvolution of Augmenting Topologies (NEAT) and Covariance-Matrix Adaptation Evolution Strategy (CMA-ES). The evolutionary algorithm employed in this notebook is the vanilla genetic algorithm without crossing-over, applying only mutation over neural network parameters (weights).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="n">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</code></pre></div></div> <h3 id="the-neural-network-model-neuro-evolution">The Neural Network Model (“Neuro”-evolution)</h3> <p>The neural network, or a multi-layer perceptron, is a universal function approximator. The neural network in PyTorch with 2 hidden layers and non-linear activation functions hyperbolic tangent (tanh) and sigmoid is defined.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">tanh1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tanh1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">net</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <h3 id="the-mutation-function-neuro-evolution">The Mutation Function (Neuro-“evolution”)</h3> <p>As with the genetic algorithm, neuroevolution can be implemented by adding an additive Gaussian noise $\epsilon\sim N(0,\sigma)$ to all neural network weights to introduce variance in the “gene pool” of the population.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torch.nn.utils</span> <span class="kn">import</span> <span class="n">parameters_to_vector</span><span class="p">,</span> <span class="n">vector_to_parameters</span>

<span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="k">return</span> <span class="nf">parameters_to_vector</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">mutate_params</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">mutated_params</span> <span class="o">=</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">vector_to_parameters</span><span class="p">(</span><span class="n">mutated_params</span><span class="p">,</span> <span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Before mutation:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">mutate_params</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">After mutation:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">Before</span> <span class="n">mutation</span><span class="p">:</span>
  <span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5949</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1591</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6217</span><span class="p">,</span>  <span class="mf">0.0710</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6687</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3964</span><span class="p">,</span>  <span class="mf">0.3319</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2988</span><span class="p">,</span>
          <span class="mf">0.6695</span><span class="p">,</span>  <span class="mf">0.4645</span><span class="p">,</span>  <span class="mf">0.2398</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2250</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5464</span><span class="p">,</span>  <span class="mf">0.2512</span><span class="p">,</span>  <span class="mf">0.0582</span><span class="p">,</span>  <span class="mf">0.0818</span><span class="p">,</span>
          <span class="mf">0.1810</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5316</span><span class="p">,</span>  <span class="mf">0.3275</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1162</span><span class="p">,</span>  <span class="mf">0.2542</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6751</span><span class="p">,</span>  <span class="mf">0.4344</span><span class="p">,</span>  <span class="mf">0.1846</span><span class="p">,</span>
          <span class="mf">0.4996</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1422</span><span class="p">,</span>  <span class="mf">0.3201</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0814</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1195</span><span class="p">,</span>  <span class="mf">0.1880</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2272</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4236</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0218</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6078</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0099</span><span class="p">,</span>  <span class="mf">0.1856</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4883</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2465</span><span class="p">,</span>  <span class="mf">0.0166</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1269</span><span class="p">,</span>
          <span class="mf">0.4119</span><span class="p">,</span>  <span class="mf">0.0229</span><span class="p">,</span>  <span class="mf">0.2381</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0007</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2959</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4865</span><span class="p">,</span>  <span class="mf">0.0240</span><span class="p">,</span>  <span class="mf">0.0228</span><span class="p">,</span>
          <span class="mf">0.2293</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0649</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1661</span><span class="p">,</span>  <span class="mf">0.0788</span><span class="p">,</span>  <span class="mf">0.2253</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1549</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2465</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0267</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.1861</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2189</span><span class="p">,</span>  <span class="mf">0.0964</span><span class="p">,</span>  <span class="mf">0.0684</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0555</span><span class="p">,</span>  <span class="mf">0.0063</span><span class="p">,</span>  <span class="mf">0.1374</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1588</span><span class="p">,</span>
          <span class="mf">0.2334</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)</span>

<span class="n">After</span> <span class="n">mutation</span><span class="p">:</span>
  <span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.6005</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2099</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5364</span><span class="p">,</span>  <span class="mf">0.1007</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5897</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5340</span><span class="p">,</span>  <span class="mf">0.3688</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3615</span><span class="p">,</span>
          <span class="mf">0.7335</span><span class="p">,</span>  <span class="mf">0.3900</span><span class="p">,</span>  <span class="mf">0.2519</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1144</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5839</span><span class="p">,</span>  <span class="mf">0.2251</span><span class="p">,</span>  <span class="mf">0.0043</span><span class="p">,</span>  <span class="mf">0.1630</span><span class="p">,</span>
          <span class="mf">0.1419</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6593</span><span class="p">,</span>  <span class="mf">0.3079</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1238</span><span class="p">,</span>  <span class="mf">0.3217</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7810</span><span class="p">,</span>  <span class="mf">0.4419</span><span class="p">,</span>  <span class="mf">0.3621</span><span class="p">,</span>
          <span class="mf">0.5246</span><span class="p">,</span>  <span class="mf">0.0064</span><span class="p">,</span>  <span class="mf">0.4284</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1177</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0700</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0537</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1281</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3613</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0873</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6996</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1507</span><span class="p">,</span>  <span class="mf">0.1944</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6326</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1384</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0384</span><span class="p">,</span>  <span class="mf">0.0323</span><span class="p">,</span>
          <span class="mf">0.3344</span><span class="p">,</span>  <span class="mf">0.0667</span><span class="p">,</span>  <span class="mf">0.1177</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1347</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3413</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5302</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1326</span><span class="p">,</span>  <span class="mf">0.3330</span><span class="p">,</span>
          <span class="mf">0.2282</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1485</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1944</span><span class="p">,</span>  <span class="mf">0.2058</span><span class="p">,</span>  <span class="mf">0.2997</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0631</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1202</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0973</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.1269</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4766</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0509</span><span class="p">,</span>  <span class="mf">0.1725</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0470</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0562</span><span class="p">,</span>  <span class="mf">0.1357</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2274</span><span class="p">,</span>
          <span class="mf">0.3410</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div></div> <h3 id="optimization-problem-circles-dataset">Optimization Problem: Circles Dataset</h3> <p>The optimization problem is the Circles dataset from Scikit-Learn, where the neural network model must learn to predict and discriminate between the inner circles (labelled 1) and outer circles (labelled 0). The Circles dataset is the reason that non-linear activation functions in the neural network architecture are needed. $X$ is 2-dimensional while $y$ is 1-dimensional.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_circles</span>

<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">0</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_circles</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">float</span><span class="p">().</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="nf">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:])</span>

<span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.5009</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.4840</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6110</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6143</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.5136</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SigmoidBackward</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/circles_dataset.png" data-zoomable=""> </div> </div> <div class="caption"> The Circles dataset. </div> <h3 id="process-1-generate-the-initial-population-of-neural-networks">Process 1: Generate the initial population of neural networks.</h3> <p>For illustration purposes, a small population size of 5 and 4 hidden units per neural network layer is used. Inspecting the first 2 neural networks in the population, neural network weights are randomly initialised. The specific initialisation method used for the weights is documented in the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html" rel="external nofollow noopener" target="_blank">PyTorch documentation</a> for interested readers.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">population_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">initial_population</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nc">Net</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n_hidden</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">)])</span>

<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">initial_population</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
  <span class="nf">print</span><span class="p">(</span><span class="nf">get_params</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>

<span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.5282</span><span class="p">,</span>  <span class="mf">0.4404</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6330</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1387</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2104</span><span class="p">,</span>  <span class="mf">0.5194</span><span class="p">,</span>  <span class="mf">0.3596</span><span class="p">,</span>  <span class="mf">0.2664</span><span class="p">,</span>
          <span class="mf">0.1044</span><span class="p">,</span>  <span class="mf">0.5380</span><span class="p">,</span>  <span class="mf">0.1583</span><span class="p">,</span>  <span class="mf">0.1221</span><span class="p">,</span>  <span class="mf">0.0324</span><span class="p">,</span>  <span class="mf">0.1239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3658</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0879</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)</span>
<span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.3366</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6526</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1909</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4681</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3542</span><span class="p">,</span>  <span class="mf">0.2475</span><span class="p">,</span>  <span class="mf">0.1892</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1961</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.2867</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4570</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3183</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2220</span><span class="p">,</span>  <span class="mf">0.1677</span><span class="p">,</span>  <span class="mf">0.2118</span><span class="p">,</span>  <span class="mf">0.1053</span><span class="p">,</span>  <span class="mf">0.3238</span><span class="p">,</span>
          <span class="mf">0.0737</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div></div> <h3 id="process-2-compute-the-fitness-of-the-population">Process 2: Compute the fitness of the population.</h3> <p>The fitness function measures the performance of an individual neural network. Because $y$ is a binary variable of values ${0,1}$, the negative binary cross entropy error (BCE) is employed, negated to reflect a higher value as more desirable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="k">return</span> <span class="o">-</span><span class="n">nn</span><span class="p">.</span><span class="nc">BCELoss</span><span class="p">()(</span><span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">fitness_function</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span> <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">])</span>

<span class="n">fitness_score</span> <span class="o">=</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">fitness_scores</span> <span class="o">=</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">initial_population</span><span class="p">)</span>

<span class="n">fitness_score</span><span class="p">,</span> <span class="n">fitness_scores</span>


<span class="p">(</span><span class="o">-</span><span class="mf">0.7065134644508362</span><span class="p">,</span>
  <span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.69943392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.70006615</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.70542192</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69766504</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.76979303</span><span class="p">]))</span>
</code></pre></div></div> <h3 id="process-3-select-the-fittest-neural-networks">Process 3: Select the fittest neural networks.</h3> <p>Select the top $k$ percentage of neural networks with the highest fitness score to form the parent subpopulation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">solution</span><span class="p">(</span><span class="n">individual</span><span class="p">):</span>
  <span class="k">return</span> <span class="nf">individual</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">round</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">fitness_scores</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()]</span>

<span class="k">def</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">fitness_scores</span><span class="p">)[</span><span class="o">-</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span><span class="p">):]]</span>

<span class="n">parent_subpopulation</span> <span class="o">=</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">initial_population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="nf">compute_fitness</span><span class="p">(</span><span class="n">parent_subpopulation</span><span class="p">)</span>

<span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.69943392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69766504</span><span class="p">])</span>
</code></pre></div></div> <h3 id="process-4-perform-reproduction-of-the-parents-to-replenish-the-population">Process 4: Perform reproduction of the parents to replenish the population.</h3> <p>In contrast to common implementations of genetic algorithms, no crossing-over is performed. Parent neural networks are simply uniformly sampled with replacement to create an identical copy as the child.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">copy</span>

<span class="k">def</span> <span class="nf">perform_reproduction</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">):</span>
  <span class="n">num_children</span> <span class="o">=</span> <span class="n">population_size</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">)</span>
  <span class="n">parents</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">,</span> <span class="n">num_children</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">,</span> <span class="p">[</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">next_population</span> <span class="o">=</span> <span class="nf">perform_reproduction</span><span class="p">(</span><span class="n">parent_subpopulation</span><span class="p">)</span>
<span class="nf">compute_fitness</span><span class="p">(</span><span class="n">next_population</span><span class="p">)</span>

<span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.69943392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69766504</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69943392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69943392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.69766504</span><span class="p">])</span>
</code></pre></div></div> <h3 id="process-5-perform-mutation-on-the-population-1">Process 5: Perform mutation on the population.</h3> <p>As explained previously, add a Gaussian noise perturbation to all parameters of the neural network.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_population_parameter</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">[</span><span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">for</span> <span class="n">net</span> <span class="ow">in</span> <span class="n">population</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
    <span class="nf">mutate_params</span><span class="p">(</span><span class="n">individual</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">population</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Before mutation:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">get_population_parameter</span><span class="p">(</span><span class="n">next_population</span><span class="p">))</span>

<span class="nf">perform_mutation</span><span class="p">(</span><span class="n">next_population</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">After mutation:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">get_population_parameter</span><span class="p">(</span><span class="n">next_population</span><span class="p">))</span>


<span class="n">Before</span> <span class="n">mutation</span><span class="p">:</span>
<span class="p">[</span><span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.5282</span><span class="p">,</span>  <span class="mf">0.4404</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6330</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1387</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2104</span><span class="p">,</span>  <span class="mf">0.5194</span><span class="p">,</span>  <span class="mf">0.3596</span><span class="p">,</span>  <span class="mf">0.2664</span><span class="p">,</span>
          <span class="mf">0.1044</span><span class="p">,</span>  <span class="mf">0.5380</span><span class="p">,</span>  <span class="mf">0.1583</span><span class="p">,</span>  <span class="mf">0.1221</span><span class="p">,</span>  <span class="mf">0.0324</span><span class="p">,</span>  <span class="mf">0.1239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3658</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0879</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.3565</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1857</span><span class="p">,</span>  <span class="mf">0.2187</span><span class="p">,</span>  <span class="mf">0.1788</span><span class="p">,</span>  <span class="mf">0.1412</span><span class="p">,</span>  <span class="mf">0.1778</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6750</span><span class="p">,</span>  <span class="mf">0.6518</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.5023</span><span class="p">,</span>  <span class="mf">0.2402</span><span class="p">,</span>  <span class="mf">0.4160</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0343</span><span class="p">,</span>  <span class="mf">0.0818</span><span class="p">,</span>  <span class="mf">0.2978</span><span class="p">,</span>  <span class="mf">0.3582</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0858</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.3332</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.5282</span><span class="p">,</span>  <span class="mf">0.4404</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6330</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1387</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2104</span><span class="p">,</span>  <span class="mf">0.5194</span><span class="p">,</span>  <span class="mf">0.3596</span><span class="p">,</span>  <span class="mf">0.2664</span><span class="p">,</span>
          <span class="mf">0.1044</span><span class="p">,</span>  <span class="mf">0.5380</span><span class="p">,</span>  <span class="mf">0.1583</span><span class="p">,</span>  <span class="mf">0.1221</span><span class="p">,</span>  <span class="mf">0.0324</span><span class="p">,</span>  <span class="mf">0.1239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3658</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0879</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.5282</span><span class="p">,</span>  <span class="mf">0.4404</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6330</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1387</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2104</span><span class="p">,</span>  <span class="mf">0.5194</span><span class="p">,</span>  <span class="mf">0.3596</span><span class="p">,</span>  <span class="mf">0.2664</span><span class="p">,</span>
          <span class="mf">0.1044</span><span class="p">,</span>  <span class="mf">0.5380</span><span class="p">,</span>  <span class="mf">0.1583</span><span class="p">,</span>  <span class="mf">0.1221</span><span class="p">,</span>  <span class="mf">0.0324</span><span class="p">,</span>  <span class="mf">0.1239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3658</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0879</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.3565</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1857</span><span class="p">,</span>  <span class="mf">0.2187</span><span class="p">,</span>  <span class="mf">0.1788</span><span class="p">,</span>  <span class="mf">0.1412</span><span class="p">,</span>  <span class="mf">0.1778</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6750</span><span class="p">,</span>  <span class="mf">0.6518</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.5023</span><span class="p">,</span>  <span class="mf">0.2402</span><span class="p">,</span>  <span class="mf">0.4160</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0343</span><span class="p">,</span>  <span class="mf">0.0818</span><span class="p">,</span>  <span class="mf">0.2978</span><span class="p">,</span>  <span class="mf">0.3582</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0858</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.3332</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)]</span>

<span class="n">After</span> <span class="n">mutation</span><span class="p">:</span>
<span class="p">[</span><span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.6775</span><span class="p">,</span>  <span class="mf">0.5253</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6425</span><span class="p">,</span>  <span class="mf">0.0200</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2527</span><span class="p">,</span>  <span class="mf">0.5128</span><span class="p">,</span>  <span class="mf">0.4704</span><span class="p">,</span>  <span class="mf">0.1674</span><span class="p">,</span>
          <span class="mf">0.0913</span><span class="p">,</span>  <span class="mf">0.3902</span><span class="p">,</span>  <span class="mf">0.1255</span><span class="p">,</span>  <span class="mf">0.2492</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1159</span><span class="p">,</span>  <span class="mf">0.0734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2054</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3601</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.1615</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.4123</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2091</span><span class="p">,</span>  <span class="mf">0.3269</span><span class="p">,</span>  <span class="mf">0.2261</span><span class="p">,</span>  <span class="mf">0.2042</span><span class="p">,</span>  <span class="mf">0.2701</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7392</span><span class="p">,</span>  <span class="mf">0.5924</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.5903</span><span class="p">,</span>  <span class="mf">0.0912</span><span class="p">,</span>  <span class="mf">0.2945</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2038</span><span class="p">,</span>  <span class="mf">0.0711</span><span class="p">,</span>  <span class="mf">0.1820</span><span class="p">,</span>  <span class="mf">0.3112</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0067</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.3152</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.6215</span><span class="p">,</span>  <span class="mf">0.5592</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0947</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3291</span><span class="p">,</span>  <span class="mf">0.4888</span><span class="p">,</span>  <span class="mf">0.3596</span><span class="p">,</span>  <span class="mf">0.2436</span><span class="p">,</span>
          <span class="mf">0.2440</span><span class="p">,</span>  <span class="mf">0.4675</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0707</span><span class="p">,</span>  <span class="mf">0.0269</span><span class="p">,</span>  <span class="mf">0.0515</span><span class="p">,</span>  <span class="mf">0.0444</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3241</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3425</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.1050</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.4444</span><span class="p">,</span>  <span class="mf">0.4725</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6944</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2502</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1153</span><span class="p">,</span>  <span class="mf">0.5679</span><span class="p">,</span>  <span class="mf">0.2696</span><span class="p">,</span>  <span class="mf">0.4509</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0502</span><span class="p">,</span>  <span class="mf">0.6541</span><span class="p">,</span>  <span class="mf">0.0673</span><span class="p">,</span>  <span class="mf">0.1718</span><span class="p">,</span>  <span class="mf">0.0901</span><span class="p">,</span>  <span class="mf">0.0092</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2689</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4209</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.0223</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">),</span> <span class="nf">tensor</span><span class="p">([</span> <span class="mf">0.2158</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1765</span><span class="p">,</span>  <span class="mf">0.0658</span><span class="p">,</span>  <span class="mf">0.1894</span><span class="p">,</span>  <span class="mf">0.0741</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1204</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7014</span><span class="p">,</span>  <span class="mf">0.5762</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.3188</span><span class="p">,</span>  <span class="mf">0.3198</span><span class="p">,</span>  <span class="mf">0.5875</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0955</span><span class="p">,</span>  <span class="mf">0.0913</span><span class="p">,</span>  <span class="mf">0.2711</span><span class="p">,</span>  <span class="mf">0.3587</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0755</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.4120</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">CatBackward</span><span class="o">&gt;</span><span class="p">)]</span>
</code></pre></div></div> <h3 id="the-neuroevolution-algorithm-all-5-processes-together">The Neuroevolution Algorithm: All 5 Processes Together</h3> <p>By combining the 5 processes together, we construct the neuroevolution algorithm and run it to find a neural network solution that models the Circles dataset well.</p> <p>Neuroevolution:</p> <ol> <li>Generate the initial population of individuals.</li> <li>Repeat until convergence: <ol> <li>Compute fitness of the population.</li> <li>Select the fittest individuals (parent subpopulation).</li> <li>Perform reproduction between parents to produce children.</li> <li>Perform mutation on the population.</li> </ol> </li> <li>Select the fittest individual of the population as the solution.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Neuroevolution hyperparameters
</span><span class="n">population_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_generations</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">mutation_sigma</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># Process 1: Generate the initial population.
</span><span class="n">population</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nc">Net</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">)])</span>

<span class="c1"># Misc: Experimental tracking
</span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">solutions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fittests</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>
  <span class="c1"># Process 2: Compute fitness of the population.
</span>  <span class="n">fitness_scores</span> <span class="o">=</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

  <span class="c1"># Process 3: Select the fittest individuals.
</span>  <span class="n">fittest_subpopulation</span> <span class="o">=</span> <span class="nf">select_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>
  
  <span class="c1"># Misc: Experimental tracking
</span>  <span class="n">fittest</span> <span class="o">=</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">)</span>
  <span class="n">fittests</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>
  <span class="n">solutions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">solution</span><span class="p">(</span><span class="n">fittest</span><span class="p">))</span>
  <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">fitness_function</span><span class="p">(</span><span class="n">fittest</span><span class="p">))</span>

  <span class="c1"># Process 4: Perform reproduction between parents.
</span>  <span class="n">children</span> <span class="o">=</span> <span class="nf">perform_reproduction</span><span class="p">(</span><span class="n">fittest_subpopulation</span><span class="p">)</span>

  <span class="c1"># Process 5: Perform mutation on the population.
</span>  <span class="n">population</span> <span class="o">=</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">mutation_sigma</span><span class="p">)</span>


<span class="c1"># Misc: Experimental tracking
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_generations</span><span class="p">),</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/ne_training_plot.png" data-zoomable=""> </div> </div> <div class="caption"> Score over generations. </div> <h3 id="experiment-result-1">Experiment Result</h3> <p>The background colours illustrate the neural network’s decision boundary, while the individual data points are the original dataset. Looking at the fittest individual neural network of the final population, the non-linear decision boundary has been correctly and well-learnt by the fittest neural network in the final population.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_individual</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
  <span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
  <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

  <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">flatten</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())):</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="nf">net</span><span class="p">(</span><span class="nc">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">])).</span><span class="nf">float</span><span class="p">()).</span><span class="n">data</span><span class="p">)</span>
  <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">bwr</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>


<span class="n">fitness_score</span> <span class="o">=</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Fittest score: </span><span class="si">{</span><span class="n">fitness_score</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">plot_individual</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>


<span class="n">Fittest</span> <span class="n">score</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.028863554820418358</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/decision_boundary.png" data-zoomable=""> </div> </div> <div class="caption"> Fitted decision boundary. </div> <p>By visualising the fittest model at each generation of neuroevolution, notice that the circular decision boundary is eventually found. For an evolutionary strategy based on novelty applied on reinforcement learning, refer to <a href="https://jetnew.io/posts/2020/11/novelty-search/" rel="external nofollow noopener" target="_blank">Part 3</a> of the Evolutionary Computation series on Novelty Search. For an introductory treatment of the genetic algorithm, refer to <a href="https://jetnew.io/posts/2020/11/genetic-algorithm/" rel="external nofollow noopener" target="_blank">Part 1</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="kn">from</span> <span class="n">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="nf">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mf">1.2</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mf">1.2</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="mf">1.2</span><span class="p">)</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">fittests</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">Y</span> <span class="o">=</span> <span class="nf">net</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">X1</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">X2</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">bwr</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Gen </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="n">ani</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_generations</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ani</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">/images/neuroevolution/neuroevolution.gif</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/neuroevolution.gif" data-zoomable=""> </div> </div> <div class="caption"> Neuroevolution on Circles dataset over generations. </div> <hr> <h2 id="novelty-search">Novelty Search</h2> <p>Novelty Search is an Evolutionary Strategy (ES) algorithm that optimises using a novelty function instead of a fitness function (like in a vanilla genetic algorithm), which has shown to produce competitive performance for exploration in reinforcement learning. The novelty of a solution is defined by how similar the solution’s behaviour is as compared to the rest of the population. The novelty score is therefore computed by its average distance from the $k$-nearest neighbours in the population.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">gym</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="n">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</code></pre></div></div> <h3 id="neuroevolution-for-reinforcement-learning">Neuroevolution for Reinforcement Learning</h3> <p>Neuroevolution is the application of evolutionary strategies to neural networks. We use a simple neural network in PyTorch, with 2 linear layers and 2 non-linear activation functions tangent and sigmoid. In deep reinforcement learning, the neural network policy $\pi: s \rightarrow a$ serves as function mapping from the observation of the environment to an action chosen by the agent. Over one episode, the agent performs an action and the state of the environment is observed by the agent, along with a reward at that particular timestep. The fitness of an individual neural network is therefore defined by the cumulative reward obtained by the agent over one episode of interacting with the environment. The environment used is <a href="https://gym.openai.com/envs/CartPole-v1/" rel="external nofollow noopener" target="_blank">CartPole-v1</a>, where the agent’s goal is to balance the pole by pushing the cart. The state observed by the agent is defined as:</p> \[Observation = [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity]\] <p>where the range of values are:</p> \[Cart Position = [-4.8,4.8]\] \[Cart Velocity = [-Inf, Inf]\] \[Pole Angle = [-24 degrees, 24 degrees]\] \[Pole Angular Velocity = [-Inf, Inf]\] <p>and the action is a single scalar discrete value:</p> \[Action = [0, 1]\] <p>where $0$ and $1$ represents the action of pushing the cart to the left and right respectively.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">tanh1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tanh1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
  <span class="k">return</span> <span class="nf">net</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">obs</span><span class="p">.</span><span class="nf">copy</span><span class="p">()).</span><span class="nf">float</span><span class="p">()).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">argmax</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>
  <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
  <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
    <span class="n">action</span> <span class="o">=</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
  <span class="k">return</span> <span class="n">total_reward</span>

<span class="k">def</span> <span class="nf">fitness_function</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">([</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">)])</span>

<span class="k">def</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">fitness_function</span><span class="p">(</span><span class="n">individual</span><span class="p">)</span> <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">fitness_scores</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()]</span>
</code></pre></div></div> <h3 id="novelty-selection">Novelty Selection</h3> <p>The main difference between neuroevolution and novelty search is the selection criterion, changed from the fitness score to the novelty score. Instead of selecting for the fittest individuals in a population, novelty search selects the most novel individuals by the novelty score with respect to the rest of the population. The novelty score indicates the novelty of an individual, defined as the average difference of an individual neural network policy $\pi$ to $k$-nearest neighbours in the population, notably in terms of their behaviour. Therefore, the behaviour of an individual $b(\pi_i)$ must be defined. We employ a simple characterisation of a neural network’s behaviour as the terminal (final) state $s_n$ in the sequence of states observed by the agent $S_{\pi_i} = [s_1, s_2, …, s_n]$ in 1 evaluation:</p> \[Behaviour(\pi_i) = Terminal(S_{\pi_i}) = s_{n}\] <p>The similarity between 2 individuals’ behaviours is simply the sum of squared difference between final observations:</p> \[Similarity(\pi_i, \pi_j) = \Vert Behaviour(\pi_i) - Behaviour(\pi_j)\Vert_2\] <p>The novelty of an individual with respect to its $k$-nearest neighbours of the population $P$ is defined by:</p> \[Novelty(\pi_i, N_{\pi_i}) = \frac{1}{|N_{\pi_i}|} \sum_{\pi_k\in N_{\pi_i}}Similarity(\pi_i, \pi_k)\] <p>where $N_{\pi_i}$ refers to the $k$-nearest neighbours of $\pi_i$. The $k$-nearest neighbours $N_{\pi_i}$ are selected by the $k$ largest similarity scores between $\pi_i$ and $\pi_{k}\in P$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/novelty_knn.jpg" data-zoomable=""> </div> </div> <div class="caption"> Local sparseness around each individual behaviour, (<a href="https://dl.acm.org/doi/10.1016/j.ins.2016.06.044" rel="external nofollow noopener" target="_blank">Naredo 2016</a>) </div> <p>As shown above, individuals in a dense region of the behaviour space have less novel behaviour, while individuals in a sparse region have most novel behaviour and are selected for.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">behaviour</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>
  <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
  <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
    <span class="n">action</span> <span class="o">=</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">obs</span>

<span class="k">def</span> <span class="nf">similarity</span><span class="p">(</span><span class="n">net1</span><span class="p">,</span> <span class="n">net2</span><span class="p">):</span>
    <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="nf">behaviour</span><span class="p">(</span><span class="n">net1</span><span class="p">),</span> <span class="nf">behaviour</span><span class="p">(</span><span class="n">net2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">b1</span> <span class="o">-</span> <span class="n">b2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_novelty</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">distance_i</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">([</span><span class="nf">similarity</span><span class="p">(</span><span class="n">population</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">population</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">])[:</span><span class="n">k</span><span class="p">]</span>
        <span class="n">distances</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">distance_i</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">distances</span>

<span class="k">def</span> <span class="nf">get_novel_subpopulation</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">novelty_scores</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">novelty_scores</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()]</span>

<span class="k">def</span> <span class="nf">select_most_novel</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">novelty_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">population</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">novelty_scores</span><span class="p">)[</span><span class="o">-</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span><span class="p">):]]</span>
</code></pre></div></div> <h3 id="perform-reproduction">Perform Reproduction</h3> <p>As with neuroevolution, reproduction among the novel parent individuals is performed by simply sampling then making a copy of the parent individual to form child individuals, replenishing the population. There is no change from the neuroevolution implementation the above section on neuroevolution.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">copy</span>

<span class="k">def</span> <span class="nf">perform_reproduction</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">):</span>
  <span class="n">num_children</span> <span class="o">=</span> <span class="n">population_size</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">)</span>
  <span class="n">parents</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">,</span> <span class="n">num_children</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">subpopulation</span><span class="p">,</span> <span class="p">[</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h3 id="perform-mutation">Perform Mutation</h3> <p>As with neuroevolution, mutation is performed by applying an additive Gaussian noise to the parameters of the neural networks. There is no change from the neuroevolution implementation in <a href="https://jetnew.io/posts/2020/11/neuroevolution/" rel="external nofollow noopener" target="_blank">Part 2</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torch.nn.utils</span> <span class="kn">import</span> <span class="n">parameters_to_vector</span><span class="p">,</span> <span class="n">vector_to_parameters</span>

<span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="k">return</span> <span class="nf">parameters_to_vector</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">mutate_params</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">mutated_params</span> <span class="o">=</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nf">get_params</span><span class="p">(</span><span class="n">net</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">vector_to_parameters</span><span class="p">(</span><span class="n">mutated_params</span><span class="p">,</span> <span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
    <span class="nf">mutate_params</span><span class="p">(</span><span class="n">individual</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">population</span>
</code></pre></div></div> <h3 id="the-novelty-search-algorithm">The Novelty Search Algorithm</h3> <p>By selecting the most novel individuals over generations, the individuals in the population will find its behavioural niche, improving exploration in the behaviour space.</p> <p>Novelty Search:</p> <ol> <li>Generate the initial population of individuals.</li> <li>Repeat until convergence: <ol> <li>Compute novelty of the population.</li> <li>Select the most novel individuals to form the parent subpopulation.</li> <li>Perform reproduction between parents to produce children.</li> <li>Perform mutation on the population.</li> </ol> </li> <li>Select the fittest individual of the population as the solution.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Novelty Search hyperparameters
</span><span class="n">population_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_generations</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">mutation_sigma</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">k_nearest</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># CartPole environment initialisation
</span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="sh">'</span><span class="s">CartPole-v1</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Neural network hyperparameters
</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span>
<span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># Process 1: Generate the initial population.
</span><span class="n">population</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nc">Net</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">)])</span>

<span class="c1"># Misc: Experimental tracking
</span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fittests</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>

  <span class="c1"># Process 2: Compute the novelty of individuals with respect to closest neighbours in the population.
</span>  <span class="n">novelty_scores</span> <span class="o">=</span> <span class="nf">compute_novelty</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k_nearest</span><span class="p">)</span>
    
  <span class="c1"># Process 3: Select the most novel individuals.
</span>  <span class="n">novel_subpopulation</span> <span class="o">=</span> <span class="nf">select_most_novel</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">novelty_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>

  <span class="c1"># Misc: Experimental tracking
</span>  <span class="n">fitness_scores</span> <span class="o">=</span> <span class="nf">compute_fitness</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>
  <span class="n">fittest</span> <span class="o">=</span> <span class="nf">get_fittest</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">)</span>
  <span class="n">fittests</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">fittest</span><span class="p">)</span>
  <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">fitness_scores</span><span class="p">))</span>

  <span class="c1"># Process 4: Perform reproduction between parents.
</span>  <span class="n">children</span> <span class="o">=</span> <span class="nf">perform_reproduction</span><span class="p">(</span><span class="n">novel_subpopulation</span><span class="p">)</span>
  <span class="n">population</span> <span class="o">=</span> <span class="nf">perform_mutation</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">mutation_sigma</span><span class="p">)</span>


<span class="c1"># Misc: Experimental tracking
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_generations</span><span class="p">),</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/ns_training_plot.png" data-zoomable=""> </div> </div> <div class="caption"> Score over generations. </div> <h3 id="experiment-results">Experiment Results</h3> <p>Plotting the novelty score against fitness score for the final population, the novelty score defined by the $k$-nearest neighbour similarity of terminal states is not linearly correlated with a high fitness score. It is important that the novelty score is not linearly correlated with the fitness score because a linear combination of the fitness score would have been used for selection, defeating the purpose of novelty-based search.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Novelty Score</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Fitness Score</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">novelty_scores</span><span class="p">,</span> <span class="n">fitness_scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/novelty-fitness.png" data-zoomable=""> </div> </div> <div class="caption"> Novelty (x-axis) is not linearly correlated with the fitness score (y-axis). </div> <p>Visualising an episode of the fittest individual shows that the novelty search algorithm has successfully achieved the goal of CartPole-v1 of balancing the pole.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="kn">from</span> <span class="n">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span>

<span class="k">def</span> <span class="nf">get_frames</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
  <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
      <span class="n">action</span> <span class="o">=</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
      <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
      <span class="n">frames</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="nf">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">rgb_array</span><span class="sh">'</span><span class="p">))</span>
  <span class="n">env</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">frames</span>

<span class="n">frames</span> <span class="o">=</span> <span class="nf">get_frames</span><span class="p">(</span><span class="n">fittest</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">screen</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">screen</span><span class="p">.</span><span class="nf">set_data</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">ani</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ani</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">/images/novelty-search/novelty_search.gif</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/evo-comp/novelty_search.gif" data-zoomable=""> </div> </div> <div class="caption"> Fitted solution trained by Novelty Search on the cartpole gym. </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"jetnew/jetnew.github.io","data-repo-id":"R_kgDOGHdCoA","data-category":"Comments","data-category-id":"DIC_kwDOGHdCoM4CTEID","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Jet New. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-17NCYRPV4N"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-17NCYRPV4N");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>